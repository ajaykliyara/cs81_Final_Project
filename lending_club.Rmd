---
title: "Untitled"
author: "Will Williamson"
date: "November 28, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Load libraries
library(stringr)
library(plyr)
library(lubridate)
library(randomForest)
library(reshape2)
library(ggplot2)
library(zoo)
library(dplyr)
library(ROCR)
library(pROC)
library(h2o)
library(caret)
library(readr)
```


```{r}
############
# Feature selection by intuition
# read the csv data file
df <- read.csv("data/LoanStats3a_securev1.csv", header = TRUE,
                stringsAsFactors = F, skip = 1)

#get rid of fields that are 80% NA
poor_coverage <- sapply(df, function(x) {
  coverage <- 1 - sum(is.na(x)) / length(x)
  coverage < 0.8
})
df <- df[,poor_coverage==FALSE]

bad_indicators <- c("Late (31-120 days)", "Default", "Charged Off")
df <- df %>%
  mutate(is_bad = ifelse(df$loan_status %in% bad_indicators, 1, 0)) %>%
  select(-loan_status)

date_format <- "%b-%Y"
df$yearmon <- as.Date(as.yearmon(df$issue_d,date_format))
df$year_issued <- year(df$yearmon)

# remove '%' from revol_util
df$revol_util <- gsub("%", "", df$revol_util)
df$revol_util <- as.numeric(df$revol_util)

df.term <- subset(df.term, year_issued < 2012)
df.term$home_ownership <- factor(df.term$home_ownership)
df.term$is_rent <- df.term$home_ownership=="RENT"

cols <- c("last_fico_range_high", "last_fico_range_low", "pub_rec_bankruptcies", "revol_util",
          "inq_last_6mths", "is_rent", "is_bad")
df.term <- df.term[,cols]

write.csv(df.term, "data/loanstats_2015_y.csv")
```

```{r}
### Automatic feature selection with caret

# ensure the results are repeatable
set.seed(7)

# define the control using a random forest selection function
control <- rfeControl(functions=rfFuncs, method="cv", number=10)

# run the RFE algorithm
df_no_na <- na.omit(df.term)
results <- rfe(df_no_na[,1:6], df_no_na[,7], sizes=c(1:7), rfeControl=control)

# summarize the results
print(results)
# list the chosen features
predictors(results)
# plot the results
plot(results, type=c("g", "o"))
```


```{r}
### Large data frame for feature selection
# read the csv data file
df <- read.csv("data/LoanStats3a_securev1.csv", header = TRUE,
                stringsAsFactors = F)

#get rid of fields that are 80% NA
poor_coverage <- sapply(df, function(x) {
  coverage <- 1 - sum(is.na(x)) / length(x)
  coverage < 0.8
})
df <- df[,poor_coverage==FALSE]

# delete columns that are obviously not going to help
col_to_delete <- c("id", "member_id", "funded_amnt", "funded_amnt_inv", "int_rate",
                   "installment", "emp_title", "verification_status", "issue_d",
                   "pymnt_plan", "url", "desc", "purpose", "title",
                   "initial_list_status", "out_prncp", "out_prncp_inv",
                   "total_pymnt", "total_pymnt_inv",
                   "total_rec_prncp", "total_rec_int", "total_rec_late_fee",
                   "recoveries", "collection_recovery_fee", "last_pymnt_d",
                   "last_pymnt_amnt", "next_pymnt_d", "last_credit_pull_d",
                   "application_type", "grade", "sub_grade", "policy_code")
df <- df %>% select(-one_of(col_to_delete))

# clean up emp_length column
df$emp_length <- str_match(df$emp_length, "[0123456789+]")
df$emp_length <- as.numeric(df$emp_length)

# remove '%' from revol_util
df$revol_util <- gsub("%", "", df$revol_util)
df$revol_util <- as.numeric(df$revol_util)

# Remove all remaining rows with NA's
df <- na.omit(df)

# remove columns which are all zeros
all_zeros <- sapply(df, function(x) {
  col_sum = 1
  if (is.numeric(x)){
      col_sum = sum(x)
  }
  col_sum == 0
})
df <- df[,all_zeros==FALSE]

# remove "months" from the term column
df$term <- str_match(df$term, "[0123456789+]")
df$term <- as.numeric(df$term)

# create a good / bad column
# bad if late more than 30 days, in default, or charged off
bad_indicators <- c("Late (16-30 days)", "Late (31-120 days)", "Default", "Charged Off")
df <- df %>%
  mutate(is_bad = ifelse(df$loan_status %in% bad_indicators, 1, 0)) %>%
  select(-loan_status)

# convert earliest credit line dates to time since epoch
df$earliest_cr_line <- as.numeric(as.Date(as.yearmon(df$earliest_cr_line, "%b-%y")))

write.csv(df, "data/loanstats_2015_large.csv")
```

```{r}
#### Random Forest Model
get_rf_grid <- function(data, factor_cols, max_num_models = 25, 
                        class_col_name = "is_bad", rf_grid_id = "rf_grid"){
  data[,factor_cols] <- as.factor(data[,factor_cols])
  
  # split into train, validation, and test sets
  splits <- h2o.splitFrame(data = data,
                           ratios = c(0.7, 0.15),  #partition data into 70%, 15%, 15% chunks
                           seed = 1)  #setting a seed will guarantee reproducibility
  train <- splits[[1]]
  valid <- splits[[2]]
  test <- splits[[3]]
  
  # Create lists which indicate independent and dependent variable names in the data
  y <- class_col_name
  x <- setdiff(names(data), class_col_name)
  
  # define a random forest search grid
  rf_search_criteria <- list(strategy = "RandomDiscrete", max_models = max_num_models)
  rf_hyper_params <- list(ntrees = c(100,200,300,400,500,600,700,800,900,1000), 
                          mtries = c(2:(ncol(data)-1)), max_depth = c(2:20)) 
  
  # fit the random forest search grid
  h2o.rf_grid <- h2o.grid("randomForest", x = x, y = y, 
                          training_frame = train,
                          validation_frame = valid,
                          hyper_params = rf_hyper_params,
                          search_criteria = rf_search_criteria,
                          seed = 3, 
                          grid_id = rf_grid_id)
  
  # extract the best model from the grid
  rf_gridperf <- h2o.getGrid(grid_id = rf_grid_id,
                             sort_by = "auc",
                             decreasing = TRUE)
  best_model <- h2o.getModel(rf_gridperf@model_ids[[1]])
  
  # make a prediction using the best model and the test data
  rf_perf <- h2o.performance(model = best_model,
                             newdata = test)
  cat("Best Random Forest Model AUC Computed on Independent Test Data: ", h2o.auc(rf_perf))
  
  return(best_model)
}
```

```{r}
## Feature Selection with H2o
h2o.init(nthreads = -1, #Number of threads -1 means use all cores on your machine
        max_mem_size = "16G")  #max mem size is the maximum memory to allocate to H2O

# read the data set
df1 <- read_csv("data/loanstats_2015_large.csv")
df1 <- df1 %>% select(-X1)
data <- as.h2o(df1)

# encode the factors as factors
factor_cols <- c("is_bad", "home_ownership", "zip_code", "addr_state")

# compute the random forest model
best_model <- get_rf_grid(data, factor_cols, 2)

# predictor importance
h2o.varimp(best_model)
h2o.varimp_plot(best_model)

# remove the last grid
h2o.rm("rf_grid")

# reduce the number of features based on the previous model results.  
# try averaging the last fico's and removing the fico high and low
df1 <- df1 %>% 
  mutate(fico = (last_fico_range_high + last_fico_range_low) / 2) %>%
  select(-c(fico_range_high, fico_range_low, last_fico_range_high, 
            last_fico_range_low))

# create a new h2o data frame
data <- as.h2o(df1)

# compute a new random forest model
best_model <- get_rf_grid(data, factor_cols, 2)

# print predictor importance and make a plot
h2o.varimp(best_model)
h2o.varimp_plot(best_model)

# select the best 12 predictors
best_predictors <- h2o.varimp(best_model)$variable
best_predictors <- best_predictors[1:12]
best_predictors <- append(best_predictors, c("is_bad"))
bar <- select_(df1, .dots = best_predictors)

# re-encode the factors removing home_ownership
factor_cols <- c("is_bad", "zip_code", "addr_state")

# remove the last grid 
h2o.rm("rf_grid")

# compute a new model with the best predictors
best_model <- get_rf_grid(data, factor_cols, 500)

# remove the last grid
h2o.rm("rf_grid")

write_csv(df1, "data/loanstats_2015_optimized.csv")
```

```{r}
## h2o random forest
# initialize the h2o engine
h2o.init(nthreads = -1, #Number of threads -1 means use all cores on your machine
         max_mem_size = "16G")  #max mem size is the maximum memory to allocate to H2O

# read the data set
data <- h2o.importFile("data/loanstats_2015_y.csv")

# remove the index column
h2o.removeVecs(data, "C1")

# encode the factors as factors
data$is_bad <- as.factor(data$is_bad)
data$is_rent <- as.factor(data$is_rent)

# split into train, validation, and test sets
splits <- h2o.splitFrame(data = data,
                         ratios = c(0.7, 0.15),  #partition data into 70%, 15%, 15% chunks
                         seed = 1)  #setting a seed will guarantee reproducibility
train <- splits[[1]]
valid <- splits[[2]]
test <- splits[[3]]

# Create lists which indicating independent and dependent variable names in the data
y <- "is_bad"
x <- setdiff(names(data), "is_bad")

# Fit an individual random forest model
rf_fit <- h2o.randomForest(x = x,
                          y = y,
                          training_frame = train,
                          model_id = "rf_fit",
                          seed = 1,
                          ntrees = 500)

# make a prediction with the test data and print the performance
rf_perf <- h2o.performance(model = rf_fit,
                           newdata = test)
h2o.auc(rf_perf)

# define a random forest search grid
rf_search_criteria <- list(strategy = "RandomDiscrete", max_models = 25)
rf_hyper_params <- list(ntrees = c(100,200,300,400,500,600,700,800,900,1000), 
                        mtries = c(2,3,4,5,6), max_depth = c(2,3,4,5,6,7,8,9,10))

# fit the random forest search grid
h2o.rf_grid <- h2o.grid("randomForest", x = x, y = y, 
                        training_frame = train,
                        hyper_params = rf_hyper_params,
                        search_criteria = rf_search_criteria,
                        seed = 3, 
                        grid_id = "rf_grid")

# extract the best model from the grid
rf_gridperf <- h2o.getGrid(grid_id = "rf_grid",
                           sort_by = "auc",
                           decreasing = TRUE)
best_model <- h2o.getModel(rf_gridperf@model_ids[[1]])

# predictor importance
h2o.varimp(best_model)
h2o.varimp_plot(best_model)


```

```{r}
########### R Random Forest
idx <- runif(nrow(df)) > 0.75
train <- df[idx==FALSE,]
test <- df[idx==TRUE,]
y_test <- factor(test$is_bad)
x_test <- test %>% select(-is_bad)

rf_fit <- randomForest(factor(is_bad) ~ ., type="classification", data=train,
                       importance=TRUE, na.action=na.omit)
test_predict <- predict(rf_fit, type = "prob", newdata = x_test)
test_roc <- roc(y_test, test_predict)
auc_score <- performance(prediction.obj = test_predict, measure = 'auc')@y.values



  # use the model to make a prediction on the independent data set
  indep_predict <- predict(rf_fit, type = "prob", newdata = indep_set)

  #AUC score
  # wew to do: Only call performance on the test set.
  auc_score <- performance(prediction.obj = train_predict, measure = 'auc')@y.values
```














